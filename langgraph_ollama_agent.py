import os
import streamlit as st
from typing import TypedDict, List
from langgraph.graph import StateGraph, END
from langchain.prompts import PromptTemplate
from langchain_community.chat_models import ChatOllama
from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage
from langchain_core.runnables.graph import MermaidDrawMethod
import tempfile
import base64
from PIL import Image as PILImage
import io

from dotenv import load_dotenv

load_dotenv()

class State(TypedDict):
    text: str
    classification: str
    entities: List[str]
    summary: str


#model
llm = ChatOllama(model="qwen2.5:7b", temperature=0.3)

# Define node functions
def classification_node(state: State):
    '''‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: ‡∏Ç‡πà‡∏≤‡∏ß, ‡∏ö‡∏•‡πá‡∏≠‡∏Å, ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢, ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡πÜ'''

    prompt = PromptTemplate(
        input_variables=["text"],
        template="‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: ‡∏Ç‡πà‡∏≤‡∏ß, ‡∏ö‡∏•‡πá‡∏≠‡∏Å, ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢, ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n\n‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:{text}\n\n‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:"
    )
    message = HumanMessage(content=prompt.format(text=state["text"]))
    classification = llm.invoke([message]).content.strip()
    return {"classification": classification}

def entity_extraction_node(state: State):
    '''‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡∏Ñ‡∏ô, ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà) ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°'''

    prompt = PromptTemplate(
        input_variables=["text"],
        template="‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡∏Ñ‡∏ô, ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà) ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ\n\n‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:{text}\n\n‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞:"
    )
    message = HumanMessage(content=prompt.format(text=state["text"]))
    entities = llm.invoke([message]).content.strip().split(", ")
    return {"entities": entities}

def summarization_node(state: State):
    '''‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏±‡πâ‡∏ô‡πÜ'''

    prompt = PromptTemplate(
        input_variables=["text"],
        template="‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏±‡πâ‡∏ô‡πÜ\n\n‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:{text}\n\n‡∏™‡∏£‡∏∏‡∏õ:"
    )
    message = HumanMessage(content=prompt.format(text=state["text"]))
    summary = llm.invoke([message]).content.strip()
    return {"summary": summary}

#Create tools and Build the workflow
workflow = StateGraph(State)

# Add nodes to the graph
workflow.add_node("classification_node", classification_node)
workflow.add_node("entity_extraction", entity_extraction_node)
workflow.add_node("summarization", summarization_node)

# Add edges to the graph
workflow.set_entry_point("classification_node") # Set the entry point of the graph
workflow.add_edge("classification_node", "entity_extraction")
workflow.add_edge("entity_extraction", "summarization")
workflow.add_edge("summarization", END)

# Compile the graph
app = workflow.compile()


# Function to create a text-based workflow representation
def get_workflow_description():
    workflow_description = """
    ```mermaid
    graph TD
        A[Start] --> B[Classification]
        B --> C[Entity Extraction]
        C --> D[Summarization]
        D --> E[End]
    ```
    """
    return workflow_description

# Streamlit UI
def main():
    st.set_page_config(
        page_title="Ollama Text Analysis Agent",
        page_icon="üìä",
        layout="wide"
    )
    
    st.title("Ollama Text Analysis Agent")
    st.write("This agent analyzes text using a workflow of classification, entity extraction, and summarization.")
    
    # Sidebar for model settings
    with st.sidebar:
        st.header("Model Settings")
        model_name = st.selectbox(
            "Select Ollama Model",
            ["qwen2.5:7b", "llama3:8b", "codegemma:7b", "llava:7b"],
            index=0
        )
        temperature = st.slider("Temperature", 0.0, 1.0, 0.8, 0.1)
        
        st.header("Workflow Visualization")
        workflow_desc = get_workflow_description()
        st.markdown(workflow_desc)
    
    # Sample text selection
    st.header("Input Text")
    
    sample_option = st.radio(
        "Choose input method:",
        ["Use sample text", "Enter your own text", "Upload text file"]
    )
    
    if sample_option == "Use sample text":
        sample_text = """
        ‡∏ô‡∏≤‡∏á‡∏°‡∏ô‡∏û‡∏£ ‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏®‡∏£‡∏µ ‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏° ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ú‡∏¢‡∏ß‡πà‡∏≤
        ‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏° ‡πÑ‡∏î‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ú‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏ô‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ 20 ‡∏ö‡∏≤‡∏ó‡∏ï‡∏•‡∏≠‡∏î‡∏™‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å‡∏™‡∏≤‡∏¢ 
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° 2568 ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÑ‡∏ß‡πâ ‡πÅ‡∏ï‡πà‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á 3 ‡∏â‡∏ö‡∏±‡∏ö 
        ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏û.‡∏£.‡∏ö. ‡∏Å‡∏≤‡∏£‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏°‡∏ß‡∏•‡∏ä‡∏ô‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ , ‡∏û.‡∏£.‡∏ö.‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏±‡πã‡∏ß‡∏£‡πà‡∏ß‡∏° 
        ‡πÅ‡∏•‡∏∞ ‡∏û.‡∏£.‡∏ö.‡∏Å‡∏≤‡∏£‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏ó‡∏≤‡∏á‡∏£‡∏≤‡∏á ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏•‡∏π‡∏Å ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤ 
        ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏µ‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏à‡∏∂‡∏á‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏¢‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ
        """
        st.text_area("Sample Text", sample_text, height=200, key="input_text", disabled=True)
        input_text = sample_text
    
    elif sample_option == "Enter your own text":
        input_text = st.text_area("Enter your text here:", height=200, key="custom_text")
    
    else:  # Upload text file
        uploaded_file = st.file_uploader("Upload a text file", type=["txt"])
        if uploaded_file is not None:
            input_text = uploaded_file.read().decode("utf-8")
            st.text_area("File content:", input_text, height=200, disabled=True)
        else:
            input_text = ""
    
    # Process button
    if st.button("Analyze Text") and input_text:
        with st.spinner("Processing text..."):
            # Update model settings if changed
            global llm
            llm = ChatOllama(model=model_name, temperature=temperature)
            
            # Process the text
            state_input = {"text": input_text}
            try:
                result = app.invoke(state_input)
                
                # Display results in tabs
                st.header("Analysis Results")
                tab1, tab2, tab3 = st.tabs(["Classification", "Entity Extraction", "Summary"])
                
                with tab1:
                    st.subheader("Text Classification")
                    st.info(result["classification"])
                
                with tab2:
                    st.subheader("Entities Extracted")
                    if result["entities"]:
                        for entity in result["entities"]:
                            st.write(f"‚Ä¢ {entity}")
                    else:
                        st.write("No entities found.")
                
                with tab3:
                    st.subheader("Text Summary")
                    st.success(result["summary"])
                
                # Save results option
                st.download_button(
                    label="Download Results",
                    data=f"""Text Analysis Results
                    
Classification: {result["classification"]}

Entities: {', '.join(result["entities"])}

Summary: {result["summary"]}
                    """,
                    file_name="text_analysis_results.txt",
                    mime="text/plain"
                )
                
            except Exception as e:
                st.error(f"Error processing text: {e}")
    elif not input_text and st.button("Analyze Text"):
        st.warning("Please enter or upload some text to analyze.")

if __name__ == "__main__":
    main()